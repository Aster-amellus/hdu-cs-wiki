# 推荐系统经典模型综述

Author: 周东霖

# 概论

## 1.1 摘要

推荐系统技术最早起源于上世纪末和本世纪初，最早是数据挖掘领域最为经典的应用之一。2012 年至 2015 年，机器学习技术进入推荐系统领域，使得这项古老的应用再次发光发热。 2016 年以来，随着深度学习的发展，大规模算力、大数据的应用的逐渐普及，基于深度学习的推荐系统研究再次成为行业热点，在工业界和学术界都占据极其重要之地。

本文旨在回顾经典的推荐系统经典模型和研究思路，但并不提供具体的推导方案，并讨论它们各自的优缺点。希望能够为后来入坑者提供一些思路。由于是个人观点陈述，未免存在遗漏和评价不当之嫌，望请见谅。

## 1.2 关键术语：

Recommender Systems(RS) : 推荐系统

Information overlaod: 信息过载

user:用户

item:物品

feedback:用户反馈

explicit feedback:显式反馈,例如用户评分

implicit feedback:隐式反馈，浏览、点击、购买等行为

## 1.3 主要任务

推荐系统的主要任务包括两方面：

评分预测(rating prediction)

物品推荐(item recommendation)

## 1.4 评价方式和评价指标

学术界通常采用离线方式进行评估，一般进行 N 折交叉验证。

优点：依赖数据集、容易验证和评估；

缺点：无法直接反映商业需求。

工业界常采用在线测试，比如 A/B test。

优点：和商业需求紧密挂钩。

缺点：成本高、风险大。

对于评分预测任务，常用评价指标包括：

Root Mean Squared Error (RMSE)
Mean Absolute Error (MAE)

对于物品推荐任务，常用评价指标包括：

Precision、Recall、F-measure、Hit Ratio(HR)
Average Precision (AP)、Mean Average Precision(MAP)
Area Under the ROC Curve (AUC)、Mean Reciprocal Rank (MRR)

Normalized Discounted Cumulative Gain (NDCG)

通常情况下，常用 @N 表示推荐前 N 个物品的性能，即 Top-N 推荐。近几年的论文常常采用 HR、NDCG 作为评价指标。

# 经典 SOTA

## 2.1 协同过滤（collaborative filtering, CF）

协同过滤是最早的一种推荐系统技术，最早用于电影推荐系统。最早开启这项研究的是明尼苏达大学的研究小组（GroupLens），随后，亚马逊研发了基于物品的协同过滤算法，并开始将 RS 部署上线，正式推向工业界。

协同过滤的方法主要包括两大类：

- User-based CF:基于用户的协同过滤[1]
- Item-based CF:基于物品的协同过滤[2,3]

## 2.2 分解模型（Factorization model）

最早的推荐系统采用的是邻域模型（neighborhood），本质上是计算物品和用户的相似度进行推荐。但是这种方法存在两个致命缺点：

- 稀疏性（sparsity）:实际应用（例如大型电商平台）中，数据非常稀疏，两个用户购买物品存在交集的情况非常少。
- 维度灾难：用户向量维度高、物品向量维度高，导致计算成本高，且无法保证准确度。

由此，分解模型横空出世。最为经典的分解模型就是矩阵分解（Matirx Factorization, MF）[4]。它的理论基础来源于奇异值分解 SVD(Singular Value Decomposition)。 基于 SVD 理论，评分矩阵可被分解成用户和物品的潜在因子，潜在因子的维度 k 远小于用户数量 m 和物品数量 n，由此可以大大降低计算量。(可以看作是后来的 embedding 技术的一个简化版)

Koren 等人提出 MF 以后，开始在最基础的矩阵分解模型上加入各种辅助信息，并衍生出分解模型的高阶版本，比如 SVD++，TimeSVD++，WRMF，BPR，SLIM 等等。

其中，特别推荐几个经典模型，它们的一些思想直到今天仍然未过时，也是学习分解模型的必备。

- SVD++[4]：加入了邻域信息之后的矩阵分解
- BPR[5]：采用贝叶斯概率思想，引入隐式反馈优化

## 2.3 高阶分解模型(high order factorization model)

矩阵分解模型包括用户和物品两类因子，在处理额外信息比如时间、标签时存在局限。处理额外信息的另一种直接做法是使用张量分解，主要的经典模型包括基于马尔可夫的分解模型 FPMC(Factorizing Personalized Markov Chains)。但是高阶张量分解开销十分巨大，各阶的交互方式不灵活。

提到高阶分解模型，不得不提推荐系统领域的元老级人物——Rendle。他提出的因子分解机模型——Factorization machines，几乎杀遍所有数据挖掘竞赛，霸榜 SOTA 数年，引领数年风骚[6]。FM——因子分解机，可以将多种信息进行高阶交互（二阶、三阶等等），但是一般到二阶以后，训练将变得异常困难，计算量也急剧增加。

当然，高阶分解的另一个相似模型，就是学术界明星-华人陈天奇在上海交大读研时提出的 SVDFeature 模型[7]。在原始论文中，FM 模型称 SVDFeature 模型仅仅是高阶 FM 的一个泛化。

后来陈天奇赴美留学，将梯度树的性能提升到极致，也就是经典 XGBoost 模型[8]，也霸榜 SOTA 数年，一时风光无两。SVDFeature 库是上海交大实验室采用 C++ 编写，XGBoost 开源版本很多，建议可以阅读前人开源代码，增加代码能力。同时，在机器学习时代，原版论文涉及很多数学推导和梯度计算，阅读这些论文，也是增进个人内功的很好法门。

## 2.4 深度模型(deep-learning models)

深度模型进入推荐系统领域大概是 16 年左右，最早将深度模型应用于推荐领域的应用主要是在评论文本挖掘领域。

评论信息中包含用户偏好、评价等反馈信息。研究者将 CNN 引入推荐系统领域，将文本映射成 word vector，并采用卷积网络训练，将 CNN 和传统的矩阵分解结合，并套上一个概率的外壳进行解释。这方面的工作主要包括 ConvMF[9]、DeepCoNN[10]。

基于 CNN 的模型主要是应用于评论文本挖掘和可解释性推荐方面，但是这种方法的计算量非常大，并且准确率不高，难以训练。个人认为这种方法仅仅是新奇，并不具备特别大的商业价值。对于推荐这种时效性非常强的应用，训练一个几百亿数量级的文本挖掘模型，却非用于自然语言领域，产生的价值和消耗的资源不成正比。

何向南在 2017 年提出 NCF，将神经网络结合协同过滤——深度协同过滤，霸榜 SOTA[11]。从此，推荐系统几乎被深度学习攻陷，各种方法层出不穷。他在中科大的团队同时开发了 NeuRec 开源框架——一个基于 Tensorflow 的推荐框架，适合新手入门。

在工业界方面，最早将深度学习应用于推荐系统领域的是 YouTobe，它的大规模推荐系统分成两步——排序和召回。排序阶段是初排，将百万级别数量级的物品进行排序，选出几百个候选物品；召回阶段是精排，根据物品特征和用户偏好对几百个物品进行细粒度排序。

## 2.5 序列推荐(sequential recommender)

前面介绍了机器学习时代的几种经典模型，接下来介绍深度序列推荐。Session based SRs 是会话推荐，Sequential recommender 是序列推荐。前者是指一个用户在一个 session 当中的点击序列，而后者更关注于物品序列顺序本身，而与用户无关。但是两者之间有着非常相似而密切的联系。

最早开始将深度引入会话推荐的模型是 GRU4Rec[12]，它直接将 RNNs 用于会话推荐系统，并采用 zero-padding 补齐序列长度不一致的问题。实际上，Padding 是常见的序列补齐技术，但是值得注意的是，有些开源代码采用的是左补齐（在序列的左边补齐，如 RecBole），有些采用的是右补齐（如 GRU4Rec，SASRec）。

2018 年的 ICDM 顶会上，加州大学圣地亚哥分校的 McAuley 团队（推荐系统领域的又一个大牛）提出的 SASRec[13]，直接将注意力机制用于序列推荐，完成 SOTA。原论文的实验部分设置十分精彩，值得论文初写者模仿和借鉴。

从此以后，基于 attention-based 的模型开始百花齐放，比如加入物品序列和物品特征序列的双路注意力 FDSA[14]、使用双向注意力机制的 BERT4Rec[15]等等。

20 年以来，由于图神经的方法渐渐成为研究热点。基于图网络的推荐系统也引起了学术界的兴趣。SR-GNN[16]是最近将 GNN 的方法用于会话推荐系统。随后，各种图方法开始爆发，目前主流的图神经网络方法包括清华大学和快手联合推出的 SURGE[17]。

# 主要会议和期刊

- ACM Conference on Recommender System (RecSys)： 推荐系统顶会
- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD 竞赛，数据挖掘顶会
- IEEE International Conference on Data Mining : ICDM，数据挖掘顶会
- International Joint Conference on Artificial Intelligence: IJCAI
- **ACM the Web Conference**: 3W
- **ACM International Conference on Web Search and Data Mining**:WSDM
- **ACM International Conference on Informaiton and Knowledge Management**:CIKM

# 国内外大牛 Follow

- Koren: 矩阵分解模型提出者，2009 年 Netflix prize 获得者
- Steffen Rendle: FM 系列提出者，工业界推荐系统大牛
- 何向南：中科大教授，NUS 博士，百万青橙奖得主，国内学术界推荐大牛，开源 NeuRec
- McAuley：加州大学圣地亚哥分校教授，北美推荐系统领域大牛，SASRec 模型
- 赵鑫：中国人民大学教授，联合开发 Recbole 开源库

# 参考文献

[1]Breese et al. 1998. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence (UAI'98), 43–52.

[2]G. Linden J. Jacobi and E. Benson, Collaborative Recommendations Using Item-to Item Similarity Mappings, US Patent 6,266,649 (to Amazon.com), Patent and Trademark Office, Washington, D.C., 2001

[3]Sarwar et al., Item-based collaborative filtering recommendation algorithms, Proceedings of the 10th international conference on World Wide Web, p.285-295,
May 01-05, 2001, Hong Kong

[4] Koren, Y. 2008. Factorization meets the neighborhood: A multifaceted collaborative filtering model [C]. Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD ’08. Las Vegas, Nevada, USA: ACM, 426–434

[5] Rendle, S., Freudenthaler, C., Gantner, Z., and Schmidt-Thieme, L. 2009b. Bpr: Bayesian personalized ranking from implicit feedback [C]. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. UAI ’09. Montreal, Quebec, Canada, 452–461.

[6] Rendle, S. 2013. Scaling factorization machines to relational data [C]. Proceedings of the 39th International Conference on Very Large Data Bases. volume 6 of Proc. VLDB Endow. Riva del Garda, Trento, Italy: VLDB Endowment, 337–348.

[7] Chen, T., Zhang, W., Lu, Q., Chen, K., Zheng, Z., and Yu, Y. 2012c. Svdfeature: a toolkit for feature-based collaborative filtering [J]. The Journal of Machine Learning Research, 13(1):3585–3588

[8] Chen, Tianqi, and Carlos Guestrin. "Xgboost: A scalable tree boosting system." Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016.

[9]Kim, Donghyun, et al. "Convolutional matrix factorization for document context-aware recommendation." Proceedings of the 10th ACM conference on recommender systems. 2016.

[10]Zheng, Lei, Vahid Noroozi, and Philip S. Yu. "Joint deep modeling of users and items using reviews for recommendation." Proceedings of the tenth ACM international conference on web search and data mining. 2017.

[11]He, Xiangnan, et al. "Neural collaborative filtering." Proceedings of the 26th international conference on world wide web. 2017.

[12] Hidasi, Balázs, et al. "Session-based recommendations with recurrent neural networks." arXiv preprint arXiv:1511.06939 (2015)

[13] Kang, Wang-Cheng, and Julian McAuley. "Self-attentive sequential recommendation." 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 2018.

[14] Tingting Zhang, Pengpeng Zhao et al. Feature-level Deeper Self-Attention Network for Sequential Recommendation.2019.

[15]Fei Sun, Jun Liu et al. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer.2019.

[16]Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan. Session-based Recommendation with Graph Neural Networks. 2019.

[17]Jianxin et al., Sequential Recommendation with Graph Neural Networks. SIGIR 2021.
